{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. more pytorch course.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mataney/PyTorchCourse/blob/master/4_more_pytorch_course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFkU3XmhFBxA",
        "colab_type": "text"
      },
      "source": [
        "# Tensorboard\n",
        "\n",
        "TensorBoard: TensorBoard provides the visualization and tooling needed for machine learning experimentation.\n",
        "\n",
        " PyTorch now (From version 1.1) natively supports TensorBoard with a simple  \n",
        " `from torch.utils.tensorboard import SummaryWriter` command.\n",
        " \n",
        " At the time of writing this tutorial there are some problems with using this (Not actively updating graphs)  \n",
        " So we will use the `torch=1.0` logging version.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udImI1VbhnNv",
        "colab_type": "text"
      },
      "source": [
        "## What should be mentioned:\n",
        "### Scalars\n",
        "### Images\n",
        "### Graphs\n",
        "- GEMM is General Matrix Multiplication\n",
        "- Checkout the panels\n",
        "  - different coloring\n",
        "  - Trace inputs\n",
        "\n",
        "### Embeddings\n",
        "- PCA (In MNIST for example this will be clustered really nice)\n",
        "- Better to pass your network embeddings as \"features\", this will be helpful to know where your network might got it wrong\n",
        "  \n",
        "Understanding exactly how to use TensorBoard to your advantage is a bit out of the scope, but you can find me here:\n",
        "\n",
        "https://www.youtube.com/watch?v=qTwKwVgZEqU (From IBM Watson's Romeo Kienzler) and  \n",
        "https://www.youtube.com/watch?v=XcHWLsVmHvk.  \n",
        "https://www.youtube.com/watch?v=eBbEDRsCmv4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CtVi6qMWVkH",
        "colab_type": "text"
      },
      "source": [
        "# TorchScript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIO7D6uB3z8n",
        "colab_type": "text"
      },
      "source": [
        "Based on: https://pytorch.org/tutorials/advanced/cpp_export.html \n",
        "\n",
        "Python is Awesome, but not for everything.\n",
        "\n",
        "For example, when we want our models to be in production, sometimes the performance python offers isn't enough.\n",
        "\n",
        "For production scenarios, C++ is very often the language of choice, even if only to bind it into other languages.\n",
        "Or, to be more honest, PyTorch backend is in C++, so making our pytorch models run on C++ will be easier than other non-Python languages.\n",
        "\n",
        "If we want to run our PyTorch module on a non-Python language we need to make it independent of Python.  \n",
        "How do we do this?  \n",
        "**TorchScript!**  \n",
        "The core data structure in `TorchScript` is the `ScriptModule`. \n",
        "\n",
        "\n",
        "### ScriptModule\n",
        "\n",
        "It is an analogue of torch’s nn.Module.  \n",
        "In `nn.Modules` methods are implemented as Python functions, but in `ScriptModules` methods are implemented as `TorchScript` functions, a statically-typed subset of Python that contains all of PyTorch’s built-in Tensor operations. This difference allows your `ScriptModules` code to run without the need for a Python interpreter.\n",
        "\n",
        "ScriptModules can be created in two ways:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7hSeDnI4azQ",
        "colab_type": "text"
      },
      "source": [
        "## Converting Your PyTorch Model to TorchScript\n",
        "\n",
        "Torch Script, a representation of a PyTorch model that can be understood, compiled and serialized by the Torch Script compiler.\n",
        "\n",
        "There exist two ways of converting a PyTorch model to Torch Script. \n",
        "- **Tracing:**  \n",
        "A mechanism in which the structure of the model is captured by evaluating it **once** using example inputs, and recording the flow of those inputs through the model. This is suitable for models that make limited use of control flow.\n",
        "- **Scripting:**  \n",
        "You can also add explicit annotations to your model that inform the Torch Script compiler that it may directly parse and compile your model code.\n",
        "\n",
        "Generally speaking, **Tracing** is easier and is meant for whenever we don't have any control flows in our code. If we can't remove those control flows, **Scripting** is required"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS5gkdqn908L",
        "colab_type": "text"
      },
      "source": [
        "## Converting to Torch Script via Tracing\n",
        "\n",
        "To convert a PyTorch model to Torch Script via tracing, you must pass an instance of your model along with an example input to the `torch.jit.trace` function. This will produce a `torch.jit.ScriptModule` object with the trace of your model evaluation embedded in the module’s forward method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5umd6Uy94B9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Use a pre defined model without control-flows\n",
        "model = torchvision.models.resnet18()\n",
        "\n",
        "# In order to save the model it requires an example of possible imports\n",
        "example = torch.rand(1, 3, 224, 224)\n",
        "\n",
        "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
        "traced_script_module = torch.jit.trace(model, example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSmDdAqXLer_",
        "colab_type": "code",
        "outputId": "7167fee6-a8a2-42fb-f8b2-0af5bc3d1909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        }
      },
      "source": [
        "traced_script_module"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TracedModule[ResNet](\n",
              "  (conv1): TracedModule[Conv2d]()\n",
              "  (bn1): TracedModule[BatchNorm2d]()\n",
              "  (relu): TracedModule[ReLU]()\n",
              "  (maxpool): TracedModule[MaxPool2d]()\n",
              "  (layer1): TracedModule[Sequential](\n",
              "    (0): TracedModule[BasicBlock](\n",
              "      (conv1): TracedModule[Conv2d]()\n",
              "      (bn1): TracedModule[BatchNorm2d]()\n",
              "      (relu): TracedModule[ReLU]()\n",
              "      (conv2): TracedModule[Conv2d]()\n",
              "      (bn2): TracedModule[BatchNorm2d]()\n",
              "    )\n",
              "    (1): TracedModule[BasicBlock](\n",
              "      (conv1): TracedModule[Conv2d]()\n",
              "      (bn1): TracedModule[BatchNorm2d]()\n",
              "      (relu): TracedModule[ReLU]()\n",
              "      (conv2): TracedModule[Conv2d]()\n",
              "      (bn2): TracedModule[BatchNorm2d]()\n",
              "    )\n",
              "  )\n",
              "  (layer2): TracedModule[Sequential](\n",
              "    (0): TracedModule[BasicBlock](\n",
              "      (conv1): TracedModule[Conv2d]()\n",
              "      (bn1): TracedModule[BatchNorm2d]()\n",
              "      (relu): TracedModule[ReLU]()\n",
              "      (conv2): TracedModule[Conv2d]()\n",
              "      (bn2): TracedModule[BatchNorm2d]()\n",
              "      (downsample): TracedModule[Sequential](\n",
              "        (0): TracedModule[Conv2d]()\n",
              "        (1): TracedModule[BatchNorm2d]()\n",
              "      )\n",
              "    )\n",
              "    (1): TracedModule[BasicBlock](\n",
              "      (conv1): TracedModule[Conv2d]()\n",
              "      (bn1): TracedModule[BatchNorm2d]()\n",
              "      (relu): TracedModule[ReLU]()\n",
              "      (conv2): TracedModule[Conv2d]()\n",
              "      (bn2): TracedModule[BatchNorm2d]()\n",
              "    )\n",
              "  )\n",
              "  (layer3): TracedModule[Sequential](\n",
              "    (0): TracedModule[BasicBlock](\n",
              "      (conv1): TracedModule[Conv2d]()\n",
              "      (bn1): TracedModule[BatchNorm2d]()\n",
              "      (relu): TracedModule[ReLU]()\n",
              "      (conv2): TracedModule[Conv2d]()\n",
              "      (bn2): TracedModule[BatchNorm2d]()\n",
              "      (downsample): TracedModule[Sequential](\n",
              "        (0): TracedModule[Conv2d]()\n",
              "        (1): TracedModule[BatchNorm2d]()\n",
              "      )\n",
              "    )\n",
              "    (1): TracedModule[BasicBlock](\n",
              "      (conv1): TracedModule[Conv2d]()\n",
              "      (bn1): TracedModule[BatchNorm2d]()\n",
              "      (relu): TracedModule[ReLU]()\n",
              "      (conv2): TracedModule[Conv2d]()\n",
              "      (bn2): TracedModule[BatchNorm2d]()\n",
              "    )\n",
              "  )\n",
              "  (layer4): TracedModule[Sequential](\n",
              "    (0): TracedModule[BasicBlock](\n",
              "      (conv1): TracedModule[Conv2d]()\n",
              "      (bn1): TracedModule[BatchNorm2d]()\n",
              "      (relu): TracedModule[ReLU]()\n",
              "      (conv2): TracedModule[Conv2d]()\n",
              "      (bn2): TracedModule[BatchNorm2d]()\n",
              "      (downsample): TracedModule[Sequential](\n",
              "        (0): TracedModule[Conv2d]()\n",
              "        (1): TracedModule[BatchNorm2d]()\n",
              "      )\n",
              "    )\n",
              "    (1): TracedModule[BasicBlock](\n",
              "      (conv1): TracedModule[Conv2d]()\n",
              "      (bn1): TracedModule[BatchNorm2d]()\n",
              "      (relu): TracedModule[ReLU]()\n",
              "      (conv2): TracedModule[Conv2d]()\n",
              "      (bn2): TracedModule[BatchNorm2d]()\n",
              "    )\n",
              "  )\n",
              "  (avgpool): TracedModule[AdaptiveAvgPool2d]()\n",
              "  (fc): TracedModule[Linear]()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCHfPGmf-LsQ",
        "colab_type": "text"
      },
      "source": [
        "The function `torch.jit.trace`:\n",
        "\n",
        "- Traces a function and return an executable ScriptModule that will be optimized using just-in-time compilation.\n",
        "- `torch.jit.trace`  expects a callable a Python function or `torch.nn.Module` that will be run with example_inputs.\n",
        "- example_inputs - a tuple of example inputs that will be passed to the function while tracing.\n",
        "\n",
        "\n",
        "The traced ScriptModule can now be evaluated identically to a regular PyTorch module:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFWQyccF-NRs",
        "colab_type": "code",
        "outputId": "9e5ea534-cda6-497e-ef4d-2b71e9370d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Just for fun, let's see what we get if we feed our model a image of 1s.\n",
        "\n",
        "output = traced_script_module(torch.ones(1, 3, 224, 224))\n",
        "output[0, :5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.8326, -0.5192, -0.1319, -0.6518,  0.1204], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taZ3YKmN-CvK",
        "colab_type": "text"
      },
      "source": [
        "## Converting to Torch Script via Annotation\n",
        "\n",
        "Assume the following simple model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaqvrafD-Vm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "class MyModule(torch.nn.Module):\n",
        "    def __init__(self, N, M):\n",
        "        super(MyModule, self).__init__()\n",
        "        self.weight = torch.nn.Parameter(torch.rand(N, M))\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.sum() > 0:\n",
        "          output = self.weight.mv(input)\n",
        "        else:\n",
        "          output = self.weight + input\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-h98x80-nBP",
        "colab_type": "text"
      },
      "source": [
        "While simple we shouldn't use Tracing here as we have a `if` statement within our forward code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBpfkx6S-vDo",
        "colab_type": "text"
      },
      "source": [
        "we can convert it to a `ScriptModule` by subclassing it from `torch.jit.ScriptModule` and adding a `@torch.jit.script_method` annotation to the model’s forward method:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFgIU1K--3tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "class MyModule(torch.jit.ScriptModule):\n",
        "    def __init__(self, N, M):\n",
        "        super(MyModule, self).__init__()\n",
        "        self.weight = torch.nn.Parameter(torch.rand(N, M))\n",
        "\n",
        "    @torch.jit.script_method\n",
        "    def forward(self, input):\n",
        "        if bool(input.sum() > 0):\n",
        "          output = self.weight.mv(input)\n",
        "        else:\n",
        "          output = self.weight + input\n",
        "        return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN1DymTQ-9TZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_script_module = MyModule(2, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUXvgi-f--9S",
        "colab_type": "code",
        "outputId": "c5c93d79-9b55-41bf-e29e-0743ba399c51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(my_script_module.__class__)\n",
        "print(my_script_module.__class__.__bases__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class '__main__.MyModule'>\n",
            "(<class 'torch.jit.ScriptModule'>,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQqniNKe_CsB",
        "colab_type": "text"
      },
      "source": [
        "Notice that `input.sum() > 0` returns a tensor of `tensor(0, dtype=torch.uint8)` or `tensor(1, dtype=torch.uint8)`.  \n",
        "Then, using the python compiles is assigned to `False` or `True`.\n",
        "\n",
        "Because we are not using Pytorch Compiler any more, we need to specify that `input.sum() > 0` returns a bool, so that `TorchScript` compiler will be able to compile accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IqyVx_r_jC6",
        "colab_type": "text"
      },
      "source": [
        "## Saving\n",
        "\n",
        "Assume we want to use the traced vesion of `resnet18`, saving is strightforward, we are still in Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5FQ_2nW_u-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traced_script_module.save(\"model.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tftSXs4g_0bQ",
        "colab_type": "text"
      },
      "source": [
        "## Loading - In C++ :shock:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLRIBPHiPfRB",
        "colab_type": "text"
      },
      "source": [
        "This we need to do somewhere we can run C++:\n",
        "\n",
        "- First, let's run in my mac the python script that runs the traced model.  \n",
        "```\n",
        "cd pytorch_course/TorchScript/python\n",
        "python create_traced_model.py\n",
        "```\n",
        "\n",
        "- Now wea have a traced model saved under `model.pt`\n",
        "- Download and extract TorchLib from https://pytorch.org/ (I had a bug in mac where I needed to `brew install libomp` and do [this](https://github.com/pytorch/pytorch/issues/14165))\n",
        "- Source code: View `pytorch_course/TorchScript/example-app/example-app.cpp`.\n",
        "- make txt file with all the dependencies: View `pytorch_course/TorchScript/example-app/CMakeLists.txt`.\n",
        "- create and go to `build` directory.\n",
        "- `cmake -DCMAKE_PREFIX_PATH=~/Downloads/libtorch/ ..`\n",
        "- make\n",
        "- `./example-app model.pt`\n",
        "- Notice the outputs are the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWJFHUJ_i6Bs",
        "colab_type": "text"
      },
      "source": [
        "# Other"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyt27NkJj_-X",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## On Top of PyTorch\n",
        "\n",
        "### AllenNLP\n",
        "\n",
        "From allenAI: https://github.com/allenai/allennlp  \n",
        "https://allennlp.org/tutorials\n",
        "### Fast.AI\n",
        "\n",
        "Started as a deep learning course for coders (http://course18.fast.ai/) resulted this repository: https://github.com/fastai/fastai\n",
        "\n",
        "Worth knowing:  \n",
        "- Example how to run on multiple GPUS [here](https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html#sphx-glr-beginner-blitz-data-parallel-tutorial-py).\n",
        "- A pytorch internal support for debugging bottlenecks in your program - [here](https://pytorch.org/docs/master/bottleneck.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B--KvvbQjmvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}