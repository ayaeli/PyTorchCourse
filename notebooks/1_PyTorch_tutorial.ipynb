{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. PyTorch_tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "ZyNXRQbz1YA2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mataney/PyTorchCourse/blob/master/notebooks/1_PyTorch_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0ncW5n2CBP-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8e7ba351-d971-405f-9878-5fc6c296b740"
      },
      "source": [
        "# Try to run this by pressing the \"play\" button\n",
        "print('Working')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working\n",
            "Working\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SBnKGLG44Bx4"
      },
      "source": [
        "![](https://github.com/pytorch/pytorch/raw/master/docs/source/_static/img/pytorch-logo-dark.png) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjKWgIdi_o44",
        "colab_type": "text"
      },
      "source": [
        "## Setting your environment:\n",
        "\n",
        "Please go to https://bit.ly/2XPl6qX (Case sensitive) or https://github.com/mataney/PyTorchCourse/tree/master/notebooks\n",
        "\n",
        "Keep this tab open as we will come back to this.\n",
        "\n",
        "As we are using a google product, that is Google Colaboratory, you should log to your google account first (Sorry about this, nothing I can do about it).\n",
        "\n",
        "Choose the first notebook `1_PyTorch_tutorial.ipynb` and click the blue `open in colab` button on the top of the notebook (If for some reason there's a problem loading it click `raw` and then copy the url from the first `href` and paste it to your browser).\n",
        "\n",
        "Then run the first cell by hovering over it and pressing the \"play\" button.\n",
        "If you haven't logged in with your google account first, It might ask you to log to your google account now.\n",
        "\n",
        "Then, try to run the cell again. It should print \"Working\".\n",
        "\n",
        "Hooray!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTqDOcy539a9",
        "colab_type": "text"
      },
      "source": [
        "#PyTorch Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvtkB_4ttYGF",
        "colab_type": "text"
      },
      "source": [
        "## Who is this course for?\n",
        "\n",
        "* People with DL basics without hands-on experience.  \n",
        "* People who want to switch from other frameworks to PyTorch.  \n",
        "* People with past experience with PyTorch hopefully will enjoy later parts of this course.\n",
        "\n",
        "### prerequisites:\n",
        "* Deep learning basics  \n",
        "* previous experience with either another DL framework (TF, Keras, Theano) or Numpy.\n",
        "* Some experience with notebooks (Jupyter or Colab) will be awesome, but by no means a must."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhUNejIbEeXG",
        "colab_type": "text"
      },
      "source": [
        "## What is PyTorch?\n",
        "\n",
        "Pytorch It’s a Python-based scientific computing package targeted at two sets of\n",
        "audiences:\n",
        "\n",
        "-  A replacement for NumPy to use the power of GPUs\n",
        "-  a deep learning research platform that provides maximum flexibility\n",
        "   and speed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyNXRQbz1YA2",
        "colab_type": "text"
      },
      "source": [
        "## Why PyTorch?\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1j6FiFB-qUPTQq5GXVR7wy8_bAFQmfchy\" />\n",
        "</p>\n",
        "\n",
        "### PyTorch Is Based On Python\n",
        "Not only is that PyTorch is based on this popular programming langauge, it doesn't reinvent the language as was done in TF 1.0. Models are Python classes etc.\n",
        "\n",
        "### Dynamic Approach To Graph Computation\n",
        "\n",
        "In a static computational graph framework (like TensorFlow) you define graph statically before a model can run. All communication with outer world is performed via `tf.Session` object and `tf.Placeholder` which are tensors that will be substituted by external data at runtime.\n",
        "\n",
        "In dynamic computational graphs (Like used in PyTorch) you can define, change and execute nodes as you go, no special session interfaces or placeholders.\n",
        "\n",
        "In the [words](https://www.fast.ai/2017/09/08/introducing-pytorch-for-fastai/) of Jeremy Howard of Fast.ai\n",
        "\n",
        "`\"With a static computation graph library like Tensorflow, once you have declaratively expressed your computation, you send it off to the GPU where it gets handled like a black box. But with a dynamic approach, you can fully dive into every level of the computation, and see exactly what is going on.\"`\n",
        "\n",
        "This also means you can debug!\n",
        "\n",
        "### Easier To Learn And Simpler To Code\n",
        "PyTorch is considerably easier to learn than any other deep learning library out there because it doesn’t travel far off from many conventional program practices. The documentation of PyTorch is also very helpful.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Source: https://www.analyticsindiamag.com/9-reasons-why-pytorch-will-become-your-favourite-deep-learning-tool/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgA6KgH6QlxF",
        "colab_type": "text"
      },
      "source": [
        "## A few words about Colaboratory\n",
        "\n",
        "Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud.\n",
        "\n",
        "With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser.\n",
        "\n",
        "Go ahead and run the next cell (using the \"play\" button or `shift+enter`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51blsA9RdvLF",
        "colab_type": "code",
        "outputId": "b9774b4c-eb04-4b3d-a3f3-43c13222c037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = 5\n",
        "y = x + 8\n",
        "y # the last line is always printed"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7Y0x1nieGoX",
        "colab_type": "text"
      },
      "source": [
        "Some usefull shortcuts:  \n",
        "(If you are familiar with jupyter notebook shortcuts, mostly, just add M before.)\n",
        "\n",
        "- `Shift + Enter` -> Run cell and select below\n",
        "- `cmd\\ctrl + M + A` -> Insert cell above.\n",
        "- `cmd\\ctrl + M + B` -> Insert cell below,\n",
        "- `cmd\\ctrl + M + D` -> Delete cell.\n",
        "- `cmd\\ctrl + M + I` -> Interrupt execution.\n",
        "- `cmd\\ctrl + M + .` -> Restart kernel\n",
        "- `cmd\\ctrl + M + M` -> Change cell to markdown\n",
        "- `cmd\\ctrl + M + Y` -> Change cell to code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_OKG5xxNQCS",
        "colab_type": "text"
      },
      "source": [
        "Colab also offers using GPUs and TPUs as the processing units for notebooks.  \n",
        "Enable this by `Runtime -> Change runtime type -> Hardware accelerator -> Choose \"GPU\"`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziWpbhumPGJc",
        "colab_type": "code",
        "outputId": "9639223c-64b2-432d-f5d7-9d4dd9effd14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSIFkBfMNIh6",
        "colab_type": "code",
        "outputId": "deb27287-5249-4477-f361-5f08f5781056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul 10 09:50:04 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8    16W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjRyF4_s1rOW",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch Tensors\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV5801azwXuq",
        "colab_type": "text"
      },
      "source": [
        "While Tensors have a deep geometrical meaning, for our case:   \n",
        "A Tensor (similarly to NumPy’s ndarrays) n-dimensional data structure containing some sort of scalar type, e.g., floats, ints, etc.\n",
        "\n",
        "Examples:\n",
        "\n",
        "rank 0 tensor is a scalar.  \n",
        "rank 1 tensor is a vector.  \n",
        "rank 2 tensor is a matrix.  \n",
        "rank 3 tensor is, well a rank-3 Tensor.  \n",
        "And so on.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edhc9Zmv1nF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmdPtZch1o3Y",
        "colab_type": "code",
        "outputId": "36f1886e-1b44-422e-dd5c-0a0b948bef2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8pSpwDOJ2ce",
        "colab_type": "text"
      },
      "source": [
        "### Tensors of different dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkgs4Fgn1xFH",
        "colab_type": "code",
        "outputId": "81bf82d7-30ef-4b4a-de8d-7ea1d29c15b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.tensor(1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g26MJ36JJwjv",
        "colab_type": "code",
        "outputId": "e5c9dad9-c302-4fdd-a520-e755a762d80b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.tensor([1, 1, 1, 1, 1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFktG5LDJy7v",
        "colab_type": "code",
        "outputId": "0861aebb-8c0e-460b-97d1-598d9aa85cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "torch.tensor([[1, 1, 1], [1, 1, 1]])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1],\n",
              "        [1, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fCviVZ02frP",
        "colab_type": "text"
      },
      "source": [
        "What can we represent with Tensors?\n",
        "\n",
        "The red value of a pixel is a rank 0 tensor of size `[]`. for example: `x = torch.tensor(211)`  \n",
        "a pixel is a rank 1 tensor of size `[3]`. for example: `x = torch.tensor([211, 35, 75])`.  \n",
        "Image is a rank 3 tensor of size `[3, m, n]`.  \n",
        "A batch of images is a rank 4 tensor of size `[b, 3, m, n]`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYNYLgTeMyec",
        "colab_type": "text"
      },
      "source": [
        "### Tensors also hold metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMhGHL2KdHRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "22fc5a1b-17ee-451d-8465-1e2aea36fe40"
      },
      "source": [
        "x = torch.zeros(size=(3,2), dtype=torch.float32, device=torch.device('cpu'), requires_grad=False)\n",
        "print(x)\n",
        "print(x.dtype)\n",
        "print(x.size()) #or x.shape\n",
        "print(x.device)\n",
        "print(x.requires_grad)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "torch.float32\n",
            "torch.Size([3, 2])\n",
            "cpu\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlNoN3esEJWc",
        "colab_type": "text"
      },
      "source": [
        "#### Possible Types:\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1wSAd_92-mrw2YvxHQizBevpPDqVLdOil\" />\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoHyfVFUTOCH",
        "colab_type": "text"
      },
      "source": [
        "#### Possible Devices:\n",
        "The `torch.device` contains a device type ('cpu' or 'cuda') and optional device ordinal for the device type. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTF04cK-3rE-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5235d400-01a1-4a7d-adf7-2f497059d8a9"
      },
      "source": [
        "torch.device('cpu')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lomgtdam3v_r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b63cf718-91b2-4636-b898-22f4db93fce4"
      },
      "source": [
        "torch.device('cuda')  # current cuda device"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9z3z3rqb3JTa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1ef605d6-33b3-4cb1-8b8d-5b62d0cf0c2b"
      },
      "source": [
        "torch.device('cuda:0')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWZ9l0AN23Bo",
        "colab_type": "text"
      },
      "source": [
        "#### Possible requires_grad:\n",
        "\n",
        "`True` and `False`\n",
        "\n",
        "More about `requires_grad` later.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-gLvnb3dlSD",
        "colab_type": "text"
      },
      "source": [
        "You can think of it as numpy ndarrays (Which hold the values, with the corresponding type and shape), but with 2 additional metadata:  \n",
        "- Device\n",
        "- requires_grad\n",
        "\n",
        "Notice `dtype=torch.float32`, `device=torch.device('cpu')` and `requires_grad=False` are all the default arguments when creating a new tensor.  \n",
        "So the initialization above is the same as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22o6gzVd3TfZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "0dafc6c0-9b21-4443-a819-26395f580221"
      },
      "source": [
        "x = torch.zeros((3,2))\n",
        "print(x)\n",
        "print(x.dtype)\n",
        "print(x.size())\n",
        "print(x.device)\n",
        "print(x.requires_grad)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "torch.float32\n",
            "torch.Size([3, 2])\n",
            "cpu\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWLMM3J_KvQm",
        "colab_type": "text"
      },
      "source": [
        "### Tensors operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBOfZ1tXwkZp",
        "colab_type": "text"
      },
      "source": [
        "Full list [here](https://pytorch.org/docs/stable/tensors.html).\n",
        "Here we will look at some of the more common operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIBI3Xj3KXCU",
        "colab_type": "text"
      },
      "source": [
        "####  `.size()` command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjx4HUbd2kx4",
        "colab_type": "code",
        "outputId": "32c2c205-ca2a-4a01-ca2d-892cfc969858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 2], [1, 2, 0], [1, 4, 0]])\n",
        "x.size()\n",
        "x"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 2],\n",
              "        [1, 2, 0],\n",
              "        [1, 4, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SbHNOfHL4PM",
        "colab_type": "text"
      },
      "source": [
        "#### `.view() command`\n",
        "Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmvDpJ-SLrUm",
        "colab_type": "code",
        "outputId": "2fdb0582-2e1b-49f0-94ea-278820a666bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        }
      },
      "source": [
        "batch_size = 128\n",
        "x = torch.empty(batch_size, 1, 8, 8).uniform_(0,1) \n",
        "# Notice What is torch.empty doing, What is .uniform() doing, what is that _ doing?\n",
        "x"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.4852, 0.7439, 0.1558,  ..., 0.9562, 0.7388, 0.6812],\n",
              "          [0.2603, 0.4302, 0.0422,  ..., 0.2092, 0.3912, 0.5243],\n",
              "          [0.8465, 0.5084, 0.5628,  ..., 0.3292, 0.6882, 0.4954],\n",
              "          ...,\n",
              "          [0.6174, 0.3276, 0.8180,  ..., 0.2425, 0.5771, 0.3050],\n",
              "          [0.2918, 0.2426, 0.9365,  ..., 0.8725, 0.4395, 0.6637],\n",
              "          [0.1778, 0.3941, 0.5332,  ..., 0.4496, 0.8314, 0.4578]]],\n",
              "\n",
              "\n",
              "        [[[0.7804, 0.5637, 0.7163,  ..., 0.1749, 0.9073, 0.3180],\n",
              "          [0.8585, 0.5553, 0.4480,  ..., 0.9352, 0.7989, 0.3535],\n",
              "          [0.7389, 0.9841, 0.5836,  ..., 0.4869, 0.1945, 0.3203],\n",
              "          ...,\n",
              "          [0.1719, 0.1185, 0.6804,  ..., 0.6511, 0.2461, 0.6553],\n",
              "          [0.3626, 0.9266, 0.4068,  ..., 0.6648, 0.2418, 0.7421],\n",
              "          [0.1657, 0.8024, 0.7070,  ..., 0.4728, 0.8675, 0.3725]]],\n",
              "\n",
              "\n",
              "        [[[0.0758, 0.4245, 0.2073,  ..., 0.4605, 0.5546, 0.9666],\n",
              "          [0.3701, 0.6401, 0.9811,  ..., 0.0348, 0.1087, 0.0419],\n",
              "          [0.8633, 0.4895, 0.0962,  ..., 0.1128, 0.8682, 0.5670],\n",
              "          ...,\n",
              "          [0.6814, 0.6326, 0.7405,  ..., 0.6134, 0.2321, 0.3466],\n",
              "          [0.3058, 0.3923, 0.3332,  ..., 0.4798, 0.2087, 0.4342],\n",
              "          [0.8756, 0.8430, 0.2833,  ..., 0.0955, 0.5980, 0.6697]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[0.9368, 0.4777, 0.4154,  ..., 0.9339, 0.8474, 0.1448],\n",
              "          [0.9915, 0.0614, 0.7035,  ..., 0.6465, 0.9545, 0.8075],\n",
              "          [0.4949, 0.0030, 0.2540,  ..., 0.4771, 0.7656, 0.1804],\n",
              "          ...,\n",
              "          [0.2993, 0.2221, 0.2422,  ..., 0.9579, 0.6671, 0.0561],\n",
              "          [0.2205, 0.6147, 0.3765,  ..., 0.2263, 0.4334, 0.5296],\n",
              "          [0.1700, 0.8950, 0.1650,  ..., 0.5935, 0.8413, 0.3498]]],\n",
              "\n",
              "\n",
              "        [[[0.5912, 0.6734, 0.9960,  ..., 0.8843, 0.2814, 0.8733],\n",
              "          [0.0566, 0.3483, 0.8332,  ..., 0.8993, 0.3024, 0.3955],\n",
              "          [0.8621, 0.2104, 0.0166,  ..., 0.6523, 0.5000, 0.4678],\n",
              "          ...,\n",
              "          [0.9671, 0.3244, 0.1101,  ..., 0.7307, 0.3917, 0.2930],\n",
              "          [0.5392, 0.1884, 0.9948,  ..., 0.0737, 0.7814, 0.1297],\n",
              "          [0.5653, 0.2039, 0.8982,  ..., 0.1908, 0.9930, 0.7310]]],\n",
              "\n",
              "\n",
              "        [[[0.9980, 0.5925, 0.0476,  ..., 0.7407, 0.7851, 0.1905],\n",
              "          [0.4230, 0.9752, 0.3648,  ..., 0.7056, 0.9569, 0.9349],\n",
              "          [0.0547, 0.9407, 0.8807,  ..., 0.1549, 0.9599, 0.1016],\n",
              "          ...,\n",
              "          [0.6763, 0.3498, 0.3350,  ..., 0.0954, 0.4066, 0.8246],\n",
              "          [0.3406, 0.0807, 0.0581,  ..., 0.9486, 0.6592, 0.6948],\n",
              "          [0.6261, 0.9941, 0.1475,  ..., 0.9403, 0.9469, 0.2841]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTQ3ugdwdwi7",
        "colab_type": "text"
      },
      "source": [
        "Think of this as a batch of 128 8\\*8 pixels images of 1 channel with values between 0-1.  \n",
        "If our model expect to get each picture as a one long tensor then:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcmURH4BfBFv",
        "colab_type": "code",
        "outputId": "5c0859aa-c373-4d57-b80a-6207e634dd91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "print(x.view(batch_size, 1, -1))\n",
        "print(x.view(batch_size, 1, -1).size())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0.4852, 0.7439, 0.1558,  ..., 0.4496, 0.8314, 0.4578]],\n",
            "\n",
            "        [[0.7804, 0.5637, 0.7163,  ..., 0.4728, 0.8675, 0.3725]],\n",
            "\n",
            "        [[0.0758, 0.4245, 0.2073,  ..., 0.0955, 0.5980, 0.6697]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.9368, 0.4777, 0.4154,  ..., 0.5935, 0.8413, 0.3498]],\n",
            "\n",
            "        [[0.5912, 0.6734, 0.9960,  ..., 0.1908, 0.9930, 0.7310]],\n",
            "\n",
            "        [[0.9980, 0.5925, 0.0476,  ..., 0.9403, 0.9469, 0.2841]]])\n",
            "torch.Size([128, 1, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wC9_tB-fPq5",
        "colab_type": "text"
      },
      "source": [
        "Or if we want everything to be concatenated:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7yq39JCOk8S",
        "colab_type": "code",
        "outputId": "5a041d4f-aa65-4800-849b-83ebef72dfb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(x.view(-1))\n",
        "print(x.view(-1).size()) # 128 * 1 * 8 * 8 = 8192"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.4852, 0.7439, 0.1558,  ..., 0.9403, 0.9469, 0.2841])\n",
            "torch.Size([8192])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxZQjZ1pUhWX",
        "colab_type": "text"
      },
      "source": [
        "Can I break it?!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8f3jXhoedzh",
        "colab_type": "code",
        "outputId": "24460995-5bda-4bf1-fa26-e49209e30052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "x.view(batch_size, 1, 65)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-afa3e6daeaae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m65\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[128, 1, 65]' is invalid for input of size 8192"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqRysOBlL73D",
        "colab_type": "text"
      },
      "source": [
        "####  Create new Tensors \n",
        "We already saw some options, but here are a few more:  \n",
        "using `rand, rand_like, zeros, ones` etc'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GrQH4DB2q0L",
        "colab_type": "code",
        "outputId": "f0907366-82cb-4ab5-c166-aa25ff1a8ce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "x = torch.zeros(5, 3)\n",
        "x"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx3I7_Cp2q8R",
        "colab_type": "code",
        "outputId": "71d651f7-35df-4c8f-d28d-44cd54d08f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "x = torch.ones(5, 3, dtype=torch.double)\n",
        "x"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHo5Qard2q4k",
        "colab_type": "code",
        "outputId": "57dca036-654e-4879-9093-060cff6a9ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "x = torch.rand(5, 3) #This is similar to what we did before (torch.empty(batch_size, 1, 8, 8).uniform_(0,1))\n",
        "x"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2135, 0.7315, 0.8543],\n",
              "        [0.8362, 0.3603, 0.7612],\n",
              "        [0.7142, 0.9070, 0.2891],\n",
              "        [0.7088, 0.5226, 0.2651],\n",
              "        [0.4001, 0.0544, 0.8978]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpwf0iCyi5OK",
        "colab_type": "code",
        "outputId": "088622d6-8842-4513-8189-c4ed9888792c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "x = torch.randn(5, 3)\n",
        "x"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8421,  0.9120,  1.4448],\n",
              "        [-1.3336,  1.4641, -0.9091],\n",
              "        [ 0.9500,  0.3838, -0.9774],\n",
              "        [ 0.6177,  0.8500,  3.1549],\n",
              "        [ 0.1438, -0.4079,  0.6336]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySSsctZ5VqIA",
        "colab_type": "text"
      },
      "source": [
        "#### *_like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2ikw3JQVOx7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c0a995a9-8c66-4ec4-c5c8-f5cf11731077"
      },
      "source": [
        "x = torch.full_like(x, 3.141592)\n",
        "x"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.1416, 3.1416, 3.1416, 3.1416],\n",
              "        [3.1416, 3.1416, 3.1416, 3.1416],\n",
              "        [3.1416, 3.1416, 3.1416, 3.1416]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8DK_WWTLh-h",
        "colab_type": "code",
        "outputId": "a4e47ae8-b4c7-4eaa-e7ba-dedbe0c6891f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "x2 = torch.rand_like(x)\n",
        "print(x2)\n",
        "print(x2.size())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4779, 0.6301, 0.9907],\n",
            "        [0.4157, 0.5428, 0.2494],\n",
            "        [0.6278, 0.4905, 0.7291],\n",
            "        [0.2552, 0.0958, 0.4178],\n",
            "        [0.9937, 0.2331, 0.4972]])\n",
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNgpzDC9V49O",
        "colab_type": "text"
      },
      "source": [
        "etc.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kq4YFEs2rEw",
        "colab_type": "text"
      },
      "source": [
        "### Operations\n",
        "\n",
        "There are multiple syntaxes for operations. In the following example, we will take a look at the addition operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qipt2eI22rOT",
        "colab_type": "code",
        "outputId": "549f288a-d00a-40b8-a61f-79918dc187e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "y = torch.rand(5, 3)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2880, 0.9275, 0.0951],\n",
            "        [0.2719, 0.1998, 0.0197],\n",
            "        [0.3824, 0.9755, 0.8949],\n",
            "        [0.5789, 0.5209, 0.7545],\n",
            "        [0.8250, 0.7413, 0.0246]])\n",
            "tensor([[0.9194, 0.4180, 0.4562],\n",
            "        [0.0152, 0.3840, 0.1168],\n",
            "        [0.8072, 0.1648, 0.2647],\n",
            "        [0.7009, 0.7676, 0.2343],\n",
            "        [0.3691, 0.5354, 0.0801]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBhrQvIWWQRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "c5c3e518-5295-44a4-be04-7632ea830e51"
      },
      "source": [
        "print(x + 1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.2880, 1.9275, 1.0951],\n",
            "        [1.2719, 1.1998, 1.0197],\n",
            "        [1.3824, 1.9755, 1.8949],\n",
            "        [1.5789, 1.5209, 1.7545],\n",
            "        [1.8250, 1.7413, 1.0246]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3Bqk-OJ3dJV",
        "colab_type": "code",
        "outputId": "f390d9b9-595c-4669-8d8c-ae70e29d90bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "print(x + y);\n",
        "print(torch.add(x, y))\n",
        "print(x.add(y))\n",
        "result = torch.empty(5, 3); torch.add(x, y, out=result); print(result)\n",
        "y.add_(x); print(y) # adds x to y"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.2074, 1.3455, 0.5513],\n",
            "        [0.2870, 0.5838, 0.1365],\n",
            "        [1.1896, 1.1404, 1.1596],\n",
            "        [1.2798, 1.2884, 0.9888],\n",
            "        [1.1941, 1.2767, 0.1047]])\n",
            "tensor([[1.2074, 1.3455, 0.5513],\n",
            "        [0.2870, 0.5838, 0.1365],\n",
            "        [1.1896, 1.1404, 1.1596],\n",
            "        [1.2798, 1.2884, 0.9888],\n",
            "        [1.1941, 1.2767, 0.1047]])\n",
            "tensor([[1.2074, 1.3455, 0.5513],\n",
            "        [0.2870, 0.5838, 0.1365],\n",
            "        [1.1896, 1.1404, 1.1596],\n",
            "        [1.2798, 1.2884, 0.9888],\n",
            "        [1.1941, 1.2767, 0.1047]])\n",
            "tensor([[1.2074, 1.3455, 0.5513],\n",
            "        [0.2870, 0.5838, 0.1365],\n",
            "        [1.1896, 1.1404, 1.1596],\n",
            "        [1.2798, 1.2884, 0.9888],\n",
            "        [1.1941, 1.2767, 0.1047]])\n",
            "tensor([[1.2074, 1.3455, 0.5513],\n",
            "        [0.2870, 0.5838, 0.1365],\n",
            "        [1.1896, 1.1404, 1.1596],\n",
            "        [1.2798, 1.2884, 0.9888],\n",
            "        [1.1941, 1.2767, 0.1047]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SvPF_Rz3kAq",
        "colab_type": "text"
      },
      "source": [
        "Any operation that mutates a tensor in-place is post-fixed with an ``_``.  \n",
        "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8Q8esbPW4bs",
        "colab_type": "code",
        "outputId": "2f988118-e76b-4f78-b23b-9fcab5707e9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2880, 0.9275, 0.0951],\n",
              "        [0.2719, 0.1998, 0.0197],\n",
              "        [0.3824, 0.9755, 0.8949],\n",
              "        [0.5789, 0.5209, 0.7545],\n",
              "        [0.8250, 0.7413, 0.0246]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6GJ1yB3OXuo",
        "colab_type": "text"
      },
      "source": [
        "### Slicing:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUsYWQ8xOV2A",
        "colab_type": "text"
      },
      "source": [
        "You can use standard NumPy-like indexing with all bells and whistles!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu891ZL93kDZ",
        "colab_type": "code",
        "outputId": "0ed63ed2-0dbb-4996-ba08-4b110342286c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(x[2, 1])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.9755)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0o_BAzE4tEB",
        "colab_type": "text"
      },
      "source": [
        "If you have a one element tensor, use ``.item()`` to get the value as a Python number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "09a99592-d609-45b1-ee97-52809f250532",
        "id": "Tbuq6r4U4sa-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.numpy())\n",
        "print(x.item())"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.5040])\n",
            "[-0.5040146]\n",
            "-0.5040146112442017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAnwOxqq3kK4",
        "colab_type": "text"
      },
      "source": [
        "### CUDA Tensors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nxchSq346QA",
        "colab_type": "code",
        "outputId": "01da5cff-d730-451a-98d5-4006d0c1e1e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR1EdpKlQcw5",
        "colab_type": "text"
      },
      "source": [
        "Tensors can be moved onto any device using the ``.to`` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itJexwtZ3kNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kshkm2MpZ1_q",
        "colab_type": "code",
        "outputId": "50be04eb-d5ac-4c0b-9436-d38176b3f757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKPLjcJ2Z5X_",
        "colab_type": "code",
        "outputId": "65899b97-e7b7-4cbf-aa24-f1db5571184d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x.device"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nkTQCH3Z0wT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = torch.ones_like(x, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkB5CKxAaAEt",
        "colab_type": "code",
        "outputId": "8337aa6a-860b-453e-9ef4-552e76b9d096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y.device"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgaV-_8JXO2A",
        "colab_type": "text"
      },
      "source": [
        "Summing over x (from CPU) and y (From GPU)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSLm1WBQW95g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "a41e0c9d-0b5f-4855-f177-b59c32988578"
      },
      "source": [
        "x + y"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-cd60f97aa77f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: expected backend CPU and dtype Float but got backend CUDA and dtype Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he9cIiXiZ91Z",
        "colab_type": "code",
        "outputId": "27ebb159-27c5-4814-cded-10a65352ba56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x = x.to(device)\n",
        "z = x + y\n",
        "print(z)\n",
        "print(z.to(\"cpu\"))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.4960], device='cuda:0')\n",
            "tensor([0.4960])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAV3fqIm3kU3",
        "colab_type": "code",
        "outputId": "3a985769-985c-4ac9-e428-ed8e1fbe30b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul 10 10:11:01 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    29W /  70W |    771MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x302hQ38Vbh",
        "colab_type": "text"
      },
      "source": [
        "# Autograd: Automatic Differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay3txZPGzyxs",
        "colab_type": "text"
      },
      "source": [
        "The distinguishing characteristic of PyTorch when it was originally released was that it provided automatic differentiation on tensors (these days, we have other cool features like TorchScript; but back then, this was it!)\n",
        "\n",
        "#### Automatic differentiation is the machinery that's responsible for training a neural network, but how does it work?\n",
        "\n",
        "Neural Networks use backpropagation to calcualte gradients.  \n",
        "These gradients are later updated using some optimization method.\n",
        "\n",
        "Central to all neural networks in PyTorch is the `autograd` package.  \n",
        "The `autograd` package provides automatic differentiation for all operations on Tensors. \n",
        "\n",
        "If you set a tensor's `.requires_grad` attribute to `True`, it starts to track all operations on it. When you finish your computation you can call ``.backward()`` and have all the gradients computed automatically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya3FoHGe0WXl",
        "colab_type": "code",
        "outputId": "ff7833a3-bfe5-446c-a36a-338f50798a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x = torch.tensor([[1, 2], [3, 4.]], requires_grad=True)\n",
        "x"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeHy81v73hx9",
        "colab_type": "code",
        "outputId": "0e02a3b9-08ac-4247-d9e6-8ff2443b3e3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y = x + torch.tensor(2) # this can also be y = x + 2\n",
        "y"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 4.],\n",
              "        [5., 6.]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWkZJ_qtUPcx",
        "colab_type": "code",
        "outputId": "8a08775a-4ee8-4905-f397-24b01752cda5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xjxgHgyUTPF",
        "colab_type": "text"
      },
      "source": [
        "Why does `y` require_grad?  \n",
        "`y` has two inputs, `x` and `torch.tensor(2)`.  \n",
        "If there’s a single input to an operation that requires gradient, its output will also require gradient. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgJaQu1LU-Hu",
        "colab_type": "text"
      },
      "source": [
        "Changing whether a tensor requires_grad or not is especially useful when you want to freeze part of your model, like wheny you want to train only later layers of a network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW19juSi5XTa",
        "colab_type": "code",
        "outputId": "c0fca67b-771d-4a64-d7a9-c315aac481c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x7f6a083ab198>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD_nhQB75amf",
        "colab_type": "code",
        "outputId": "544c0d58-d5b4-4b28-e198-8bfbb5c5d559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "z = y * y * 3\n",
        "z"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 27.,  48.],\n",
              "        [ 75., 108.]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG19U9Ni5fJC",
        "colab_type": "code",
        "outputId": "76d5974b-2338-4e8c-91a4-622361026b23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "out = z.mean()\n",
        "out"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(64.5000, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZb076TU5hjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aio8PYK282e",
        "colab_type": "text"
      },
      "source": [
        "## The Autograd graph we created:\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1P-b6SlPNuyTE-4H3Uoa_hkHjXn_JPADa\" width=\"75%\" height=\"75%\"/>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpGbByZF4SM0",
        "colab_type": "text"
      },
      "source": [
        "## How is the gradient computed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbmEbw595k0R",
        "colab_type": "code",
        "outputId": "0d51e297-39cf-4132-b2a9-63df151d8700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x.grad"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.5000, 6.0000],\n",
              "        [7.5000, 9.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1KQogCa5oZY",
        "colab_type": "text"
      },
      "source": [
        "Let’s call the ``out`` *Tensor* “$o$”.  \n",
        "We want to find the gradient of the leaves with respect to $o$.  \n",
        "$o =\\frac{1}{4}\\sum_j 3(x_j+2)^2$,  \n",
        "\n",
        "Therefore,\n",
        "$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$,  hence,  \n",
        "$\\frac{\\partial o}{\\partial x_1} = 4.5$  \n",
        "$\\frac{\\partial o}{\\partial x_2} = 6$  \n",
        "$\\frac{\\partial o}{\\partial x_3} = 7.5$  \n",
        "$\\frac{\\partial o}{\\partial x_4} = 9$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sowO3sLJ5nKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.grad #Why?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc7rT3Ry5wGR",
        "colab_type": "text"
      },
      "source": [
        "Given all of this, let's go ahead and write our first Neural model."
      ]
    }
  ]
}