{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. PyTorch_tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "ZyNXRQbz1YA2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mataney/PyTorchCourse/blob/master/1_PyTorch_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SBnKGLG44Bx4"
      },
      "source": [
        "![](https://github.com/pytorch/pytorch/raw/master/docs/source/_static/img/pytorch-logo-dark.png) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTqDOcy539a9",
        "colab_type": "text"
      },
      "source": [
        "#PyTorch Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvtkB_4ttYGF",
        "colab_type": "text"
      },
      "source": [
        "## Who is this course for?\n",
        "\n",
        "* People with DL basics without hands-on experience.  \n",
        "* People want to switch from other frameworks to PyTorch.  \n",
        "* People with past experience with PyTorch hopefully will enjoy later parts of this course.\n",
        "\n",
        "### prerequisites:\n",
        "* Deep learning basics  \n",
        "* previous experience with either another DL framework (TF, Keras, Theano) or Numpy.\n",
        "* Some experience with notebooks (Jupyter or Colab) will be awesome, but by no means a must."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhUNejIbEeXG",
        "colab_type": "text"
      },
      "source": [
        "## What is PyTorch?\n",
        "\n",
        "Pytorch It’s a Python-based scientific computing package targeted at two sets of\n",
        "audiences:\n",
        "\n",
        "-  A replacement for NumPy to use the power of GPUs\n",
        "-  a deep learning research platform that provides maximum flexibility\n",
        "   and speed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyNXRQbz1YA2",
        "colab_type": "text"
      },
      "source": [
        "## Why PyTorch?\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1j6FiFB-qUPTQq5GXVR7wy8_bAFQmfchy\" />\n",
        "</p>\n",
        "\n",
        "### PyTorch Is Based On Python\n",
        "Not only is that PyTorch is based on this popular programming langauge, it doesn't reinvent the language as was done in TF 1.0. Models are Python classes etc.\n",
        "\n",
        "### Dynamic Approach To Graph Computation\n",
        "\n",
        "In the [words](https://www.fast.ai/2017/09/08/introducing-pytorch-for-fastai/) of Jeremy Howard of Fast.ai\n",
        "\n",
        "`\"With a static computation graph library like Tensorflow, once you have declaratively expressed your computation, you send it off to the GPU where it gets handled like a black box. But with a dynamic approach, you can fully dive into every level of the computation, and see exactly what is going on.\"`\n",
        "\n",
        "This also means you can debug!\n",
        "\n",
        "### Easier To Learn And Simpler To Code\n",
        "PyTorch is considerably easier to learn than any other deep learning library out there because it doesn’t travel far off from many conventional program practices. The documentation of PyTorch is also very brilliant and helpful for beginners.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Source: https://www.analyticsindiamag.com/9-reasons-why-pytorch-will-become-your-favourite-deep-learning-tool/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgA6KgH6QlxF",
        "colab_type": "text"
      },
      "source": [
        "## A few words about Colaboratory\n",
        "\n",
        "Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud.\n",
        "\n",
        "With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser.\n",
        "\n",
        "Go ahead and run the next cell (using the \"play\" button or `shift+enter`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51blsA9RdvLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = 5\n",
        "y = x + 8\n",
        "y # the last line is always printed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7Y0x1nieGoX",
        "colab_type": "text"
      },
      "source": [
        "Some usefull shortcuts:  \n",
        "(If you are familiar with jupyter notebook shortcuts, mostly, just add M before.)\n",
        "\n",
        "- `Shift + Enter` -> Run cell and select below\n",
        "- `cmd\\ctrl + M + A` -> Insert cell above.\n",
        "- `cmd\\ctrl + M + B` -> Insert cell below,\n",
        "- `cmd\\ctrl + M + D` -> Delete cell.\n",
        "- `cmd\\ctrl + M + I` -> Interrupt execution.\n",
        "- `cmd\\ctrl + M + .` -> Restart kernel\n",
        "- `cmd\\ctrl + M + M` -> Change cell to markdown\n",
        "- `cmd\\ctrl + M + Y` -> Change cell to code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_OKG5xxNQCS",
        "colab_type": "text"
      },
      "source": [
        "Colab also offers using GPUs and TPUs as the processing units for notebooks.  \n",
        "Enable this by `Runtime -> Change runtime type -> Hardware accelerator -> Choose \"GPU\"`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziWpbhumPGJc",
        "colab_type": "code",
        "outputId": "8c6db740-f057-4f89-aca6-89c4c4eec39a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSIFkBfMNIh6",
        "colab_type": "code",
        "outputId": "7e9f22d5-73f6-4480-96f7-39faa920ffae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu May 30 08:29:51 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    16W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjRyF4_s1rOW",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch Tensors\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV5801azwXuq",
        "colab_type": "text"
      },
      "source": [
        "While Tensors have a deep geometrical meaning, for our case:   \n",
        "A Tensor (similarly to NumPy’s ndarrays) n-dimensional data structure containing some sort of scalar type, e.g., floats, ints, etc.\n",
        "\n",
        "Examples:\n",
        "\n",
        "rank 0 tensor is a scalar.  \n",
        "rank 1 tensor is a vector.  \n",
        "rank 2 tensor is a matrix.  \n",
        "rank 3 tensor is, well a rank-3 Tensor.  \n",
        "And so on.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edhc9Zmv1nF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmdPtZch1o3Y",
        "colab_type": "code",
        "outputId": "6b7a96dd-c3ff-4584-934a-42c1533aa4dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8pSpwDOJ2ce",
        "colab_type": "text"
      },
      "source": [
        "### Tensors of different dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkgs4Fgn1xFH",
        "colab_type": "code",
        "outputId": "c28ebe74-d185-4d36-a5f6-437863983904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.tensor(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g26MJ36JJwjv",
        "colab_type": "code",
        "outputId": "da6b9837-9557-4fe9-c6a9-7bec6d21c1e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.tensor([1, 1, 1, 1, 1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFktG5LDJy7v",
        "colab_type": "code",
        "outputId": "2e098df6-d8fd-4474-d4f1-8cf795b58fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "torch.tensor([[1, 1, 1], [1, 1, 1]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1],\n",
              "        [1, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYNYLgTeMyec",
        "colab_type": "text"
      },
      "source": [
        "Tensors additional holds metadata describing the size of the tensor, the type of the elements in contains (dtype), what device the tensor lives on (CPU memory? CUDA memory?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNqzXqE1Mtyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([[1, 1, 1], [1, 1, 1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnC_CKo0NA4d",
        "colab_type": "code",
        "outputId": "76677441-ea41-4ac8-f3e1-515dc386af4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(x.dtype)\n",
        "print(x.size())\n",
        "print(x.device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.int64\n",
            "torch.Size([2, 3])\n",
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fCviVZ02frP",
        "colab_type": "text"
      },
      "source": [
        "What can we represent with Tensors?\n",
        "\n",
        "The red value of a pixel is a rank 0 tensor of size `[]`. for example: `x = torch.tensor(211)`  \n",
        "a pixel is a rank 1 tensor of size `[3]`. for example: `x = torch.tensor([211, 35, 75])`.  \n",
        "Image is a rank 3 tensor of size `[3, m, n]`.  \n",
        "A batch of images is a rank 4 tensor of size `[b, 3, m, n]`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76JiN-cS2jBP",
        "colab_type": "text"
      },
      "source": [
        "Correspondingly, `b` sentences of max number of words `l` is a `[b, l]` rank 2 tensor. (How do we represent words here?!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWLMM3J_KvQm",
        "colab_type": "text"
      },
      "source": [
        "### Tensors operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBOfZ1tXwkZp",
        "colab_type": "text"
      },
      "source": [
        "A full list of all Pytorch Tensor command is out of the scope of this short tutorial, but you can find a full list [here](https://pytorch.org/docs/stable/tensors.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIBI3Xj3KXCU",
        "colab_type": "text"
      },
      "source": [
        "####  `.size()` command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjx4HUbd2kx4",
        "colab_type": "code",
        "outputId": "105ebb99-5df2-471a-ce2b-15322163a185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 2], [1, 2, 0], [1, 4, 0]])\n",
        "x.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SbHNOfHL4PM",
        "colab_type": "text"
      },
      "source": [
        "#### `.view() command`\n",
        "Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmvDpJ-SLrUm",
        "colab_type": "code",
        "outputId": "53257321-043a-47e4-ef39-25b906a5d0f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        }
      },
      "source": [
        "batch_size = 128\n",
        "x = torch.Tensor(batch_size, 1, 8, 8).uniform_(0,1) \n",
        "# Notice What is torch.Tensor doing, What is .uniform() doing, what is that _ doing?\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0224, 0.5473, 0.1301,  ..., 0.8104, 0.4795, 0.1169],\n",
              "          [0.8711, 0.1058, 0.2307,  ..., 0.2592, 0.7447, 0.8252],\n",
              "          [0.0328, 0.9294, 0.0173,  ..., 0.0965, 0.2975, 0.1814],\n",
              "          ...,\n",
              "          [0.5378, 0.6870, 0.0532,  ..., 0.1323, 0.6397, 0.3537],\n",
              "          [0.9086, 0.7785, 0.4218,  ..., 0.0026, 0.6026, 0.2018],\n",
              "          [0.9405, 0.4619, 0.4235,  ..., 0.2185, 0.1650, 0.6001]]],\n",
              "\n",
              "\n",
              "        [[[0.2866, 0.1342, 0.8596,  ..., 0.6903, 0.5981, 0.9573],\n",
              "          [0.9737, 0.5249, 0.7475,  ..., 0.2851, 0.3029, 0.0200],\n",
              "          [0.6805, 0.6752, 0.1373,  ..., 0.7908, 0.4116, 0.6273],\n",
              "          ...,\n",
              "          [0.8170, 0.4058, 0.0923,  ..., 0.1232, 0.4805, 0.6503],\n",
              "          [0.3600, 0.8495, 0.1442,  ..., 0.1406, 0.1660, 0.6563],\n",
              "          [0.8562, 0.3802, 0.2658,  ..., 0.0469, 0.0970, 0.6353]]],\n",
              "\n",
              "\n",
              "        [[[0.0314, 0.6246, 0.2731,  ..., 0.4140, 0.0973, 0.7565],\n",
              "          [0.2044, 0.4815, 0.1652,  ..., 0.3925, 0.8297, 0.0747],\n",
              "          [0.8592, 0.8964, 0.6740,  ..., 0.9935, 0.4954, 0.1266],\n",
              "          ...,\n",
              "          [0.0707, 0.9668, 0.0124,  ..., 0.2755, 0.4445, 0.2607],\n",
              "          [0.3669, 0.1216, 0.4896,  ..., 0.1193, 0.8193, 0.7886],\n",
              "          [0.8093, 0.7875, 0.8907,  ..., 0.2847, 0.5035, 0.6295]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[0.7709, 0.3989, 0.2022,  ..., 0.7571, 0.6967, 0.1928],\n",
              "          [0.2901, 0.9313, 0.4786,  ..., 0.3676, 0.8509, 0.7612],\n",
              "          [0.9474, 0.3961, 0.4565,  ..., 0.5834, 0.4296, 0.9014],\n",
              "          ...,\n",
              "          [0.5084, 0.1052, 0.6490,  ..., 0.1204, 0.3959, 0.9675],\n",
              "          [0.2259, 0.4239, 0.4710,  ..., 0.7330, 0.3742, 0.2904],\n",
              "          [0.4195, 0.6908, 0.4002,  ..., 0.2984, 0.6023, 0.1148]]],\n",
              "\n",
              "\n",
              "        [[[0.7832, 0.1671, 0.0951,  ..., 0.4429, 0.9827, 0.2042],\n",
              "          [0.2044, 0.3442, 0.5416,  ..., 0.4840, 0.5371, 0.5713],\n",
              "          [0.8025, 0.8294, 0.0441,  ..., 0.2543, 0.1776, 0.4577],\n",
              "          ...,\n",
              "          [0.5843, 0.1807, 0.7490,  ..., 0.3196, 0.4891, 0.3817],\n",
              "          [0.0615, 0.4380, 0.6812,  ..., 0.9048, 0.0444, 0.2194],\n",
              "          [0.6846, 0.2298, 0.0609,  ..., 0.7783, 0.8377, 0.4670]]],\n",
              "\n",
              "\n",
              "        [[[0.0278, 0.9214, 0.7377,  ..., 0.4244, 0.1899, 0.5168],\n",
              "          [0.5624, 0.0877, 0.0172,  ..., 0.1820, 0.6385, 0.7615],\n",
              "          [0.3068, 0.7587, 0.3440,  ..., 0.7577, 0.2517, 0.8140],\n",
              "          ...,\n",
              "          [0.2786, 0.3633, 0.2657,  ..., 0.8451, 0.8004, 0.2402],\n",
              "          [0.3908, 0.0920, 0.8910,  ..., 0.5737, 0.7915, 0.0033],\n",
              "          [0.6688, 0.1911, 0.9419,  ..., 0.7944, 0.5650, 0.2327]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTQ3ugdwdwi7",
        "colab_type": "text"
      },
      "source": [
        "Think of this as a batch of 128 8\\*8 pixels images of 1 channel with values between 0-1 (Like MNIST).  \n",
        "If our model expect to get each picture as a one long tensor then:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8f3jXhoedzh",
        "colab_type": "code",
        "outputId": "ac5904c7-ee5a-4d5f-c0ae-61c7e67f6622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "x.view(batch_size, 1, 64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0224, 0.5473, 0.1301,  ..., 0.2185, 0.1650, 0.6001]],\n",
              "\n",
              "        [[0.2866, 0.1342, 0.8596,  ..., 0.0469, 0.0970, 0.6353]],\n",
              "\n",
              "        [[0.0314, 0.6246, 0.2731,  ..., 0.2847, 0.5035, 0.6295]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.7709, 0.3989, 0.2022,  ..., 0.2984, 0.6023, 0.1148]],\n",
              "\n",
              "        [[0.7832, 0.1671, 0.0951,  ..., 0.7783, 0.8377, 0.4670]],\n",
              "\n",
              "        [[0.0278, 0.9214, 0.7377,  ..., 0.7944, 0.5650, 0.2327]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsGlXyXXe-jM",
        "colab_type": "text"
      },
      "source": [
        "Or Simply:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcmURH4BfBFv",
        "colab_type": "code",
        "outputId": "00914d93-7812-431c-c6f9-a12f996fe65a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "print(x.view(batch_size, 1, -1))\n",
        "print(x.view(batch_size, 1, -1).size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0.0224, 0.5473, 0.1301,  ..., 0.2185, 0.1650, 0.6001]],\n",
            "\n",
            "        [[0.2866, 0.1342, 0.8596,  ..., 0.0469, 0.0970, 0.6353]],\n",
            "\n",
            "        [[0.0314, 0.6246, 0.2731,  ..., 0.2847, 0.5035, 0.6295]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.7709, 0.3989, 0.2022,  ..., 0.2984, 0.6023, 0.1148]],\n",
            "\n",
            "        [[0.7832, 0.1671, 0.0951,  ..., 0.7783, 0.8377, 0.4670]],\n",
            "\n",
            "        [[0.0278, 0.9214, 0.7377,  ..., 0.7944, 0.5650, 0.2327]]])\n",
            "torch.Size([128, 1, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wC9_tB-fPq5",
        "colab_type": "text"
      },
      "source": [
        "Or if we want everything to be concatenated:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7yq39JCOk8S",
        "colab_type": "code",
        "outputId": "cb3ef878-9ab0-4fea-a66a-8c27de1f2cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x.view(-1))\n",
        "print(x.view(-1).size()) # 128 * 1 * 8 * 8 = 8192"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0224, 0.5473, 0.1301,  ..., 0.7944, 0.5650, 0.2327])\n",
            "torch.Size([8192])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqRysOBlL73D",
        "colab_type": "text"
      },
      "source": [
        "####  Create new Tensors \n",
        "We already saw some options, but here are a few more:  \n",
        "using `rand, rand_like, zeros, ones` etc'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHo5Qard2q4k",
        "colab_type": "code",
        "outputId": "03d3899c-4dcd-4b2b-db09-78a47c7e0b6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.rand(5, 3) #This is similar to what we did before (torch.Tensor(batch_size, 1, 8, 8).uniform_(0,1))\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1781, 0.9358, 0.5117],\n",
              "        [0.6625, 0.5836, 0.0556],\n",
              "        [0.2777, 0.2435, 0.5239],\n",
              "        [0.3116, 0.7860, 0.9668],\n",
              "        [0.4547, 0.5733, 0.1565]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpwf0iCyi5OK",
        "colab_type": "code",
        "outputId": "d4b8004c-ba01-4b7a-d9fe-2f991d84b3c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.randn(5, 3)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7941,  0.3381, -1.7987],\n",
              "        [-1.2812,  1.2838, -2.0384],\n",
              "        [ 0.0526,  0.4470, -0.5046],\n",
              "        [ 0.6519, -1.7166, -0.7014],\n",
              "        [-0.1864,  0.3468, -0.3179]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GrQH4DB2q0L",
        "colab_type": "code",
        "outputId": "fa20904f-e2ab-46fd-a798-9bdae57dbdd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.zeros(5, 3)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx3I7_Cp2q8R",
        "colab_type": "code",
        "outputId": "52f5d101-a6d7-4207-eafe-c318e29a81f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.ones(5, 3, dtype=torch.double)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8DK_WWTLh-h",
        "colab_type": "code",
        "outputId": "0822b8a4-5c72-461b-b01e-13e71941dfa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "x = torch.randn_like(x, dtype=torch.float)    \n",
        "print(x)\n",
        "print(x.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0853, -0.7478,  1.5835],\n",
            "        [ 1.5661, -0.1871, -1.2070],\n",
            "        [-1.6379,  0.6363, -1.0752],\n",
            "        [ 1.9427, -1.4612, -0.0936],\n",
            "        [-0.8668, -0.7588,  0.0227]])\n",
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kq4YFEs2rEw",
        "colab_type": "text"
      },
      "source": [
        "### Operations\n",
        "\n",
        "There are multiple syntaxes for operations. In the following example, we will take a look at the addition operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qipt2eI22rOT",
        "colab_type": "code",
        "outputId": "94712601-f532-4fe7-815c-6009de979d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "y = torch.rand(5, 3)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5401, 0.8365, 0.6008],\n",
            "        [0.9074, 0.6449, 0.9891],\n",
            "        [0.0683, 0.3595, 0.8435],\n",
            "        [0.5144, 0.1852, 0.5656],\n",
            "        [0.1754, 0.6969, 0.8043]])\n",
            "tensor([[0.7263, 0.3191, 0.4224],\n",
            "        [0.3959, 0.9381, 0.5635],\n",
            "        [0.0013, 0.9569, 0.1686],\n",
            "        [0.7091, 0.9666, 0.6392],\n",
            "        [0.7147, 0.4288, 0.2951]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3Bqk-OJ3dJV",
        "colab_type": "code",
        "outputId": "0a0b5283-3ecb-4630-889c-3b7dd996919a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "print(x + y);\n",
        "print(torch.add(x, y))\n",
        "result = torch.empty(5, 3); torch.add(x, y, out=result); print(result)\n",
        "y.add_(x); print(y) # adds x to y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.2665, 1.1556, 1.0232],\n",
            "        [1.3034, 1.5830, 1.5526],\n",
            "        [0.0696, 1.3164, 1.0122],\n",
            "        [1.2235, 1.1518, 1.2049],\n",
            "        [0.8900, 1.1257, 1.0993]])\n",
            "tensor([[1.2665, 1.1556, 1.0232],\n",
            "        [1.3034, 1.5830, 1.5526],\n",
            "        [0.0696, 1.3164, 1.0122],\n",
            "        [1.2235, 1.1518, 1.2049],\n",
            "        [0.8900, 1.1257, 1.0993]])\n",
            "tensor([[1.2665, 1.1556, 1.0232],\n",
            "        [1.3034, 1.5830, 1.5526],\n",
            "        [0.0696, 1.3164, 1.0122],\n",
            "        [1.2235, 1.1518, 1.2049],\n",
            "        [0.8900, 1.1257, 1.0993]])\n",
            "tensor([[1.2665, 1.1556, 1.0232],\n",
            "        [1.3034, 1.5830, 1.5526],\n",
            "        [0.0696, 1.3164, 1.0122],\n",
            "        [1.2235, 1.1518, 1.2049],\n",
            "        [0.8900, 1.1257, 1.0993]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SvPF_Rz3kAq",
        "colab_type": "text"
      },
      "source": [
        "Any operation that mutates a tensor in-place is post-fixed with an ``_``.  \n",
        "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6GJ1yB3OXuo",
        "colab_type": "text"
      },
      "source": [
        "### Slicing:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUsYWQ8xOV2A",
        "colab_type": "text"
      },
      "source": [
        "You can use standard NumPy-like indexing with all bells and whistles!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu891ZL93kDZ",
        "colab_type": "code",
        "outputId": "1513681b-88de-4af9-a3ae-8d9c5e29f399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x[:, 1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.8365, 0.6449, 0.3595, 0.1852, 0.6969])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0o_BAzE4tEB",
        "colab_type": "text"
      },
      "source": [
        "If you have a one element tensor, use ``.item()`` to get the value as a Python number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aa5a5dc5-aec5-428a-a1ca-898432c312d2",
        "id": "Tbuq6r4U4sa-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item()) # This also detaches the gradient tree (More on this later)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3262])\n",
            "0.3262418508529663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAnwOxqq3kK4",
        "colab_type": "text"
      },
      "source": [
        "### CUDA Tensors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nxchSq346QA",
        "colab_type": "code",
        "outputId": "846a3eb9-2265-4b47-ab0c-fc77b9fb93f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR1EdpKlQcw5",
        "colab_type": "text"
      },
      "source": [
        "Tensors can be moved onto any device using the ``.to`` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itJexwtZ3kNt",
        "colab_type": "code",
        "outputId": "2d83398f-b472-44f0-c94f-7f06b047c872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "y = torch.ones_like(x, device=device)\n",
        "x = x.to(device)\n",
        "z = x + y\n",
        "print(z)\n",
        "print(z.to(\"cpu\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.3262], device='cuda:0')\n",
            "tensor([1.3262])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAV3fqIm3kU3",
        "colab_type": "code",
        "outputId": "c57e390c-b33f-4048-871d-9deca9f1c217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu May 30 08:30:05 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    28W /  70W |    771MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x302hQ38Vbh",
        "colab_type": "text"
      },
      "source": [
        "# Autograd: Automatic Differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay3txZPGzyxs",
        "colab_type": "text"
      },
      "source": [
        "The distinguishing characteristic of PyTorch when it was originally released was that it provided automatic differentiation on tensors (these days, we have other cool features like TorchScript; but back then, this was it!)\n",
        "\n",
        "What does automatic differentiation do? It's the machinery that's responsible for training a neural network.\n",
        "\n",
        "Neural Networks uses backpropagation to calcualte gradients.  \n",
        "These gradients are later updated using some optimization method.\n",
        "\n",
        "Central to all neural networks in PyTorch is the `autograd` package.  \n",
        "The `autograd` package provides automatic differentiation for all operations on Tensors. \n",
        "\n",
        "`torch.Tensor` is the central class of the package. If you set its attribute `.requires_grad` as `True`, it starts to track all operations on it. When you finish your computation you can call ``.backward()`` and have all the gradients computed automatically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya3FoHGe0WXl",
        "colab_type": "code",
        "outputId": "ba77d06e-a894-4c47-84e7-18d4acec9b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float, requires_grad=True)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeHy81v73hx9",
        "colab_type": "code",
        "outputId": "e28cdfb6-8286-4161-d1d3-374660d45187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y = x + 2\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 4.],\n",
              "        [5., 6.]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWkZJ_qtUPcx",
        "colab_type": "code",
        "outputId": "d1ae89d0-8870-4c5e-b090-738da08347ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xjxgHgyUTPF",
        "colab_type": "text"
      },
      "source": [
        "Why does `y` require_grad?  \n",
        "`y` has two inputs, `x` and `2`.  \n",
        "If there’s a single input to an operation that requires gradient, its output will also require gradient. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgJaQu1LU-Hu",
        "colab_type": "text"
      },
      "source": [
        "Changing whether a tensor requires_grad or not is especially useful when you want to freeze part of your model, like wheny you want to train only later layers of a network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW19juSi5XTa",
        "colab_type": "code",
        "outputId": "3a600d47-ed84-4602-b793-ba77f743f0bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x7fc7fd82b048>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD_nhQB75amf",
        "colab_type": "code",
        "outputId": "3d7d613f-2ff2-47c8-8247-8e1d8d1a48be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "z = y * y * 3\n",
        "z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 27.,  48.],\n",
              "        [ 75., 108.]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG19U9Ni5fJC",
        "colab_type": "code",
        "outputId": "6d99b386-b7b9-404e-f0e1-4251fc247f1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "out = z.mean()\n",
        "out"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(64.5000, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZb076TU5hjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aio8PYK282e",
        "colab_type": "text"
      },
      "source": [
        "## The Autograd graph we created:\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1P-b6SlPNuyTE-4H3Uoa_hkHjXn_JPADa\" width=\"75%\" height=\"75%\"/>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpGbByZF4SM0",
        "colab_type": "text"
      },
      "source": [
        "## How is the gradient computed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbmEbw595k0R",
        "colab_type": "code",
        "outputId": "40c8b588-d4e3-4f08-f997-70e55e3178f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.5000, 6.0000],\n",
              "        [7.5000, 9.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1KQogCa5oZY",
        "colab_type": "text"
      },
      "source": [
        "Let’s call the ``out`` *Tensor* “$o$”.  \n",
        "We want to find the gradient of the leaves with respect to $o$.  \n",
        "$\\frac{\\partial o}{\\partial x_i} = \\frac{1}{4}\\sum_j 3(x_j+2)^2$,  \n",
        "\n",
        "Therefore,\n",
        "$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$,  hence,  \n",
        "$\\frac{\\partial o}{\\partial x_1} = 4.5$  \n",
        "$\\frac{\\partial o}{\\partial x_2} = 6$  \n",
        "$\\frac{\\partial o}{\\partial x_3} = 7.5$  \n",
        "$\\frac{\\partial o}{\\partial x_4} = 9$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sowO3sLJ5nKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.grad #Why?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc7rT3Ry5wGR",
        "colab_type": "text"
      },
      "source": [
        "Given all of this, let's go ahead and write our first Neural model."
      ]
    }
  ]
}